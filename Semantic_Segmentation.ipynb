{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "9lq2ul_pftdl",
    "outputId": "724972cf-95a5-4f47-bab1-88411ae7dcba"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oP5sBNYWXX23",
    "outputId": "1c18b9cc-62ce-4dac-a2c7-ba23e0486226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage of gpu: False\n",
      "Built with CUDA: False\n"
     ]
    }
   ],
   "source": [
    "# 查看是否可以使用GPU\n",
    "\n",
    "print (\"Usage of gpu: {}\".format(tf.test.is_gpu_available())) \n",
    "print (\"Built with CUDA: {}\".format(tf.test.is_built_with_cuda()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xLrrVH1gdn_"
   },
   "source": [
    "## 加载训练数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HuiwZp8fBhuS"
   },
   "outputs": [],
   "source": [
    "def train_value():\n",
    "  x_train,y_train=[],[]\n",
    "  k=os.listdir('train_png/')\n",
    "  for img in k:\n",
    "    val=cv.imread('train_png/'+img)\n",
    "    x_train.append(np.array(val))\n",
    "  k=os.listdir('train_masks_png/')\n",
    "  for img in k:\n",
    "    val=cv.imread('train_masks_png/'+img)\n",
    "    val = cv.cvtColor(val, cv.COLOR_BGR2GRAY)\n",
    "    res=cv.resize(val,(256,256))\n",
    "    res=np.expand_dims(res,axis=2)\n",
    "    y_train.append(np.array(res))\n",
    "  return x_train,y_train\n",
    "x_train_img,y_train_mask=train_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对训练集数据进行标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbhYqy5DigvJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 256, 256, 3) (12, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_img=np.asarray(x_train_img)\n",
    "y_train_mask=np.asarray(y_train_mask)\n",
    "\n",
    "x_train_img_m=np.mean(x_train_img,axis=0,keepdims=True)\n",
    "x_train_img_s=np.std(x_train_img,axis=0,keepdims=True)\n",
    "\n",
    "x_train_img=(x_train_img-x_train_img_m)/x_train_img_s\n",
    "y_train_mask=y_train_mask*(1./255)\n",
    "print(x_train_img.shape,y_train_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 加载验证数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RndgeEhnDf2d"
   },
   "outputs": [],
   "source": [
    "def val_value():\n",
    "  x_val,y_val, name_list = [],[], []\n",
    "  k=os.listdir('val_png/')\n",
    "  for img in k:\n",
    "    val=cv.imread('val_png/'+img)\n",
    "    x_val.append(np.array(val))\n",
    "  k=os.listdir('val_masks_png/')\n",
    "  for img in k:\n",
    "    val=cv.imread('val_masks_png/'+img)\n",
    "    val = cv.cvtColor(val,cv.COLOR_BGR2GRAY)\n",
    "    res=cv.resize(val,(256,256))\n",
    "    res=np.expand_dims(res,axis=2)\n",
    "    y_val.append(np.array(res))\n",
    "    name_list.append(img)\n",
    "  return x_val, y_val, name_list\n",
    "x_val_img,y_val_mask, val_name_list = val_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对验证集数据进行标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n0Qm7IX5zkcs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 256, 256, 3) (6, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "x_val_img=np.asarray(x_val_img)\n",
    "y_val_mask=np.asarray(y_val_mask)\n",
    "\n",
    "x_val_img_m=np.mean(x_val_img,axis=0,keepdims=True)\n",
    "x_val_img_s=np.std(x_val_img,axis=0,keepdims=True)\n",
    "\n",
    "x_val_img=(x_val_img-x_val_img_m)/x_val_img_s\n",
    "y_val_mask=y_val_mask*(1./255)\n",
    "\n",
    "print (x_val_img.shape,y_val_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 使用tf.keras构建网络模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 损失函数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qe_eDWEPSEti"
   },
   "outputs": [],
   "source": [
    "# dice系数与dice损失函数\n",
    "# dice 系数\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (K.sum(y_true_f**2) + K.sum(y_pred_f**2) + 1)\n",
    "\n",
    "# dice 损失函数\n",
    "def dice_loss(y_true,y_pred):\n",
    "    return 1-dice_coef(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "# 二分类交叉熵损失\n",
    "def binary_crossentropy(y_true,y_pred):\n",
    "    return tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "# 联合损失\n",
    "def combine_loss(y_true,y_pred):\n",
    "    return 0.3 * dice_loss(y_true,y_pred) + 0.7 * binary_crossentropy(y_true,y_pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 网络模型构建"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "# 构建卷积层：3 X 3卷积 + BN层 +ReLU激活函数\n",
    "def conv3X3_bn_relu(input, out_channels):\n",
    "\n",
    "    out = tf.keras.layers.Conv2D(filters=out_channels, kernel_size=(3, 3), strides=(1, 1),\n",
    "                                     padding=\"same\", kernel_initializer='he_normal')(input)\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    out = tf.keras.activations.relu(out)\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "# 构建 AC Block\n",
    "def ACBlock(input, out_channels):\n",
    "\n",
    "    out_33 = tf.keras.layers.Conv2D(out_channels, (3, 3), kernel_initializer='he_normal',\n",
    "                                   padding='same')(input)\n",
    "    out_33 = tf.keras.layers.BatchNormalization()(out_33)\n",
    "\n",
    "    out_13 = tf.keras.layers.Conv2D(out_channels, (1, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                   padding='same')(input)\n",
    "    out_13 = tf.keras.layers.BatchNormalization()(out_13)\n",
    "\n",
    "    out_31 = tf.keras.layers.Conv2D(out_channels, (3, 1), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                   padding='same')(input)\n",
    "    out_31 = tf.keras.layers.BatchNormalization()(out_31)\n",
    "\n",
    "    out = tf.keras.layers.Add()([tf.keras.layers.Add()([out_33, out_13]), out_31])\n",
    "    out = tf.keras.activations.relu(out)\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "# SENet 通道自注意力机制\n",
    "# 构建 SE Block\n",
    "def SEBlock(input):\n",
    "\n",
    "    [N, H, W, C] = input.shape\n",
    "\n",
    "    avg_input = tf.keras.layers.GlobalAvgPool2D()(input)  # 在特征图的高和宽维度上进行全剧平均值池化\n",
    "    se_fc_0 = tf.keras.layers.Dense(C // 2, activation=tf.keras.activations.relu)(avg_input)\n",
    "    se_fc_1 = tf.keras.layers.Dense(C, activation=tf.keras.activations.sigmoid)(se_fc_0)\n",
    "\n",
    "    out = tf.keras.layers.Multiply()([input, se_fc_1])\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "# AC + Att +UNet模型\n",
    "def AC_Att_UNet(input_img):\n",
    "    \n",
    "    map_down_1 = conv3X3_bn_relu(input_img, 64)\n",
    "    map_down_1 = conv3X3_bn_relu(map_down_1, 64)\n",
    "\n",
    "    map_down_2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(map_down_1)\n",
    "    map_down_2 = ACBlock(map_down_2, 128)\n",
    "    map_down_2 = ACBlock(map_down_2, 128)\n",
    "\n",
    "    map_down_3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(map_down_2)\n",
    "    map_down_3 = ACBlock(map_down_3, 256)\n",
    "    map_down_3 = ACBlock(map_down_3, 256)\n",
    "\n",
    "    map_down_4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(map_down_3)\n",
    "    map_down_4 = ACBlock(map_down_4, 512)\n",
    "    map_down_4 = ACBlock(map_down_4, 512)\n",
    "\n",
    "    map_down_5 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(map_down_4)\n",
    "    map_down_5 = ACBlock(map_down_5, 1024)\n",
    "    map_down_5 = ACBlock(map_down_5, 1024)\n",
    "\n",
    "    map_up_4 = tf.keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(map_down_5)\n",
    "    map_down_4 = SEBlock(map_down_4)\n",
    "    map_up_4 = tf.keras.layers.concatenate([map_up_4, map_down_4])\n",
    "    map_up_4 = ACBlock(map_up_4, 512)\n",
    "    map_up_4 = ACBlock(map_up_4, 512)\n",
    "\n",
    "    map_up_3 = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(map_up_4)\n",
    "    map_down_3 = SEBlock(map_down_3)\n",
    "    map_up_3 = tf.keras.layers.concatenate([map_up_3, map_down_3])\n",
    "    map_up_3 = ACBlock(map_up_3, 256)\n",
    "    map_up_3 = ACBlock(map_up_3, 256)\n",
    "\n",
    "    map_up_2 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(map_up_3)\n",
    "    map_down_2 = SEBlock(map_down_2)\n",
    "    map_up_2 = tf.keras.layers.concatenate([map_up_2, map_down_2])\n",
    "    map_up_2 = ACBlock(map_up_2, 256)\n",
    "    map_up_2 = ACBlock(map_up_2, 256)\n",
    "\n",
    "    map_up_1 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(map_up_2)\n",
    "    map_down_1 = SEBlock(map_down_1)\n",
    "    map_up_1 = tf.keras.layers.concatenate([map_up_1, map_down_1])\n",
    "    map_up_1 = ACBlock(map_up_1, 256)\n",
    "    map_up_1 = ACBlock(map_up_1, 256)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(map_up_1)\n",
    "    model = Model(inputs=input_img, outputs=outputs)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9tNa-_7ewVYV"
   },
   "source": [
    "# 准备训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "8xarMxcMwohM",
    "outputId": "6f43d703-40a5-4694-f0e5-d866ca56e2bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 256, 256, 64) 1792        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 256, 256, 64) 256         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_41 (TensorFlow [(None, 256, 256, 64 0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 256, 256, 64) 36928       tf_op_layer_Relu_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 256, 256, 64) 256         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_42 (TensorFlow [(None, 256, 256, 64 0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 128, 128, 64) 0           tf_op_layer_Relu_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 128, 128, 128 73856       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 128, 128, 128 24704       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 128, 128, 128 512         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 128, 128, 128 512         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 128, 128, 128 24704       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 128, 128, 128 0           batch_normalization_116[0][0]    \n",
      "                                                                 batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 128, 128, 128 512         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 128, 128, 128 0           add_71[0][0]                     \n",
      "                                                                 batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_43 (TensorFlow [(None, 128, 128, 12 0           add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 128, 128, 128 147584      tf_op_layer_Relu_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 128, 128, 128 49280       tf_op_layer_Relu_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 128, 128, 128 512         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 128, 128, 128 512         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 128, 128, 128 49280       tf_op_layer_Relu_43[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 128, 128, 128 0           batch_normalization_119[0][0]    \n",
      "                                                                 batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 128, 128, 128 512         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 128, 128, 128 0           add_73[0][0]                     \n",
      "                                                                 batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_44 (TensorFlow [(None, 128, 128, 12 0           add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 64, 64, 128)  0           tf_op_layer_Relu_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 64, 64, 256)  295168      max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 64, 64, 256)  98560       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 64, 64, 256)  1024        conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 64, 64, 256)  1024        conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 64, 64, 256)  98560       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 64, 64, 256)  0           batch_normalization_122[0][0]    \n",
      "                                                                 batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 64, 64, 256)  1024        conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, 64, 64, 256)  0           add_75[0][0]                     \n",
      "                                                                 batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_45 (TensorFlow [(None, 64, 64, 256) 0           add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 64, 64, 256)  590080      tf_op_layer_Relu_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 64, 64, 256)  196864      tf_op_layer_Relu_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 64, 64, 256)  1024        conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 64, 64, 256)  1024        conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 64, 64, 256)  196864      tf_op_layer_Relu_45[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 64, 64, 256)  0           batch_normalization_125[0][0]    \n",
      "                                                                 batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 64, 64, 256)  1024        conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 64, 64, 256)  0           add_77[0][0]                     \n",
      "                                                                 batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_46 (TensorFlow [(None, 64, 64, 256) 0           add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 32, 32, 256)  0           tf_op_layer_Relu_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 32, 32, 512)  1180160     max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 32, 32, 512)  393728      max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 32, 32, 512)  2048        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 32, 32, 512)  2048        conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 32, 32, 512)  393728      max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 32, 32, 512)  0           batch_normalization_128[0][0]    \n",
      "                                                                 batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 32, 32, 512)  2048        conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 32, 32, 512)  0           add_79[0][0]                     \n",
      "                                                                 batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_47 (TensorFlow [(None, 32, 32, 512) 0           add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 32, 32, 512)  2359808     tf_op_layer_Relu_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 32, 32, 512)  786944      tf_op_layer_Relu_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 32, 32, 512)  2048        conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 32, 32, 512)  2048        conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 32, 32, 512)  786944      tf_op_layer_Relu_47[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 32, 32, 512)  0           batch_normalization_131[0][0]    \n",
      "                                                                 batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 32, 32, 512)  2048        conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 32, 32, 512)  0           add_81[0][0]                     \n",
      "                                                                 batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_48 (TensorFlow [(None, 32, 32, 512) 0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 16, 16, 512)  0           tf_op_layer_Relu_48[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 16, 16, 1024) 4719616     max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 16, 16, 1024) 1573888     max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 16, 16, 1024) 4096        conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 16, 16, 1024) 4096        conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 16, 16, 1024) 1573888     max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 16, 16, 1024) 0           batch_normalization_134[0][0]    \n",
      "                                                                 batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 16, 16, 1024) 4096        conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 16, 16, 1024) 0           add_83[0][0]                     \n",
      "                                                                 batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_49 (TensorFlow [(None, 16, 16, 1024 0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 16, 16, 1024) 9438208     tf_op_layer_Relu_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 16, 16, 1024) 3146752     tf_op_layer_Relu_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 16, 16, 1024) 4096        conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 16, 16, 1024) 4096        conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 16, 16, 1024) 3146752     tf_op_layer_Relu_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 16, 16, 1024) 0           batch_normalization_137[0][0]    \n",
      "                                                                 batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 16, 16, 1024) 4096        conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 512)          0           tf_op_layer_Relu_48[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 16, 16, 1024) 0           add_85[0][0]                     \n",
      "                                                                 batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 256)          131328      global_average_pooling2d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_50 (TensorFlow [(None, 16, 16, 1024 0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 512)          131584      dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 32, 32, 512)  2097664     tf_op_layer_Relu_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 32, 32, 512)  0           tf_op_layer_Relu_48[0][0]        \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 1024) 0           conv2d_transpose_7[0][0]         \n",
      "                                                                 multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 32, 32, 512)  4719104     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 32, 32, 512)  1573376     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 32, 32, 512)  2048        conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 32, 32, 512)  2048        conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 32, 32, 512)  1573376     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 32, 32, 512)  0           batch_normalization_140[0][0]    \n",
      "                                                                 batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 32, 32, 512)  2048        conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 32, 32, 512)  0           add_87[0][0]                     \n",
      "                                                                 batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_51 (TensorFlow [(None, 32, 32, 512) 0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 32, 32, 512)  2359808     tf_op_layer_Relu_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 32, 32, 512)  786944      tf_op_layer_Relu_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 32, 32, 512)  2048        conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 32, 32, 512)  2048        conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 32, 32, 512)  786944      tf_op_layer_Relu_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 32, 32, 512)  0           batch_normalization_143[0][0]    \n",
      "                                                                 batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 32, 32, 512)  2048        conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_8 (Glo (None, 256)          0           tf_op_layer_Relu_46[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 32, 32, 512)  0           add_89[0][0]                     \n",
      "                                                                 batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          32896       global_average_pooling2d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_52 (TensorFlow [(None, 32, 32, 512) 0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          33024       dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 64, 64, 256)  524544      tf_op_layer_Relu_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 64, 64, 256)  0           tf_op_layer_Relu_46[0][0]        \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 64, 64, 512)  0           conv2d_transpose_8[0][0]         \n",
      "                                                                 multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 64, 64, 256)  1179904     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 64, 64, 256)  393472      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 64, 64, 256)  1024        conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 64, 64, 256)  1024        conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 64, 64, 256)  393472      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 64, 64, 256)  0           batch_normalization_146[0][0]    \n",
      "                                                                 batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 64, 64, 256)  1024        conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 64, 64, 256)  0           add_91[0][0]                     \n",
      "                                                                 batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_53 (TensorFlow [(None, 64, 64, 256) 0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 64, 64, 256)  590080      tf_op_layer_Relu_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 64, 64, 256)  196864      tf_op_layer_Relu_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 64, 64, 256)  1024        conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 64, 64, 256)  1024        conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 64, 64, 256)  196864      tf_op_layer_Relu_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 64, 64, 256)  0           batch_normalization_149[0][0]    \n",
      "                                                                 batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 64, 64, 256)  1024        conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 128)          0           tf_op_layer_Relu_44[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 64, 64, 256)  0           add_93[0][0]                     \n",
      "                                                                 batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 64)           8256        global_average_pooling2d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_54 (TensorFlow [(None, 64, 64, 256) 0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          8320        dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 128, 128, 128 131200      tf_op_layer_Relu_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 128, 128, 128 0           tf_op_layer_Relu_44[0][0]        \n",
      "                                                                 dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 128, 128, 256 0           conv2d_transpose_9[0][0]         \n",
      "                                                                 multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 128, 128, 256 590080      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 128, 128, 256 196864      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 128, 128, 256 1024        conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 128, 128, 256 1024        conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 128, 128, 256 196864      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 128, 128, 256 0           batch_normalization_152[0][0]    \n",
      "                                                                 batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 128, 128, 256 1024        conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 128, 128, 256 0           add_95[0][0]                     \n",
      "                                                                 batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_55 (TensorFlow [(None, 128, 128, 25 0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 128, 128, 256 590080      tf_op_layer_Relu_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 128, 128, 256 196864      tf_op_layer_Relu_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 128, 128, 256 1024        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 128, 128, 256 1024        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 128, 128, 256 196864      tf_op_layer_Relu_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_97 (Add)                    (None, 128, 128, 256 0           batch_normalization_155[0][0]    \n",
      "                                                                 batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 128, 128, 256 1024        conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_10 (Gl (None, 64)           0           tf_op_layer_Relu_42[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 128, 128, 256 0           add_97[0][0]                     \n",
      "                                                                 batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 32)           2080        global_average_pooling2d_10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_56 (TensorFlow [(None, 128, 128, 25 0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64)           2112        dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 256, 256, 128 131200      tf_op_layer_Relu_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 256, 256, 64) 0           tf_op_layer_Relu_42[0][0]        \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 256, 256, 192 0           conv2d_transpose_10[0][0]        \n",
      "                                                                 multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 256, 256, 256 442624      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 256, 256, 256 147712      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 256, 256, 256 1024        conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 256, 256, 256 1024        conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 256, 256, 256 147712      concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_99 (Add)                    (None, 256, 256, 256 0           batch_normalization_158[0][0]    \n",
      "                                                                 batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 256, 256, 256 1024        conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_98 (Add)                    (None, 256, 256, 256 0           add_99[0][0]                     \n",
      "                                                                 batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_57 (TensorFlow [(None, 256, 256, 25 0           add_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 256, 256, 256 590080      tf_op_layer_Relu_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 256, 256, 256 196864      tf_op_layer_Relu_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 256, 256, 256 1024        conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 256, 256, 256 1024        conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 256, 256, 256 196864      tf_op_layer_Relu_57[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_101 (Add)                   (None, 256, 256, 256 0           batch_normalization_161[0][0]    \n",
      "                                                                 batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 256, 256, 256 1024        conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_100 (Add)                   (None, 256, 256, 256 0           add_101[0][0]                    \n",
      "                                                                 batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Relu_58 (TensorFlow [(None, 256, 256, 25 0           add_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 256, 256, 1)  257         tf_op_layer_Relu_58[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 53,136,097\n",
      "Trainable params: 53,097,441\n",
      "Non-trainable params: 38,656\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model=AC_Att_UNet(input_img=Input(shape=(256,256,3)))\n",
    "# print(\"AC_Att_UNet...\")\n",
    "# model.summary()  # 打印模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Ap-Qpi_xDFQ"
   },
   "outputs": [],
   "source": [
    "# 使用Adam优化器，联合损失函数，评估指标使用准确率和dice系数\n",
    "LEARNING_RATE = 0.01  # 学习率\n",
    "adam = optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer='adam',loss=combine_loss,metrics= ['accuracy', dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "hPUF0HtIqZCA",
    "outputId": "a4312817-c7ef-4882-fb6a-52b7eb8868f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "model_path=\"{}_best.hdf5\".format('my_model')\n",
    "# 保存模型\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1,save_best_only=True, mode='min', save_weights_only = False)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=3,verbose=1, mode='min', epsilon=0.0001, cooldown=1, min_lr=1e-7)\n",
    "early = EarlyStopping(monitor=\"val_loss\",mode=\"min\",patience=7) \n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n46zk86MzkdJ",
    "outputId": "4a01bbe5-f281-449d-ffd1-d339f604a5fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 12 steps, validate on 6 samples\n",
      "Epoch 1/2\n",
      "11/12 [==========================>...] - ETA: 11s - loss: 0.4448 - accuracy: 0.8477 - dice_coef: 0.9117 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 00001: val_loss improved from inf to 131932979.66667, saving model to my_model_best.hdf5\n",
      "12/12 [==============================] - 180s 15s/step - loss: 0.4371 - accuracy: 0.8494 - dice_coef: 0.9133 - val_loss: 131932979.6667 - val_accuracy: 0.9247 - val_dice_coef: 0.9602\n",
      "Epoch 2/2\n",
      "11/12 [==========================>...] - ETA: 9s - loss: 0.3191 - accuracy: 0.9029 - dice_coef: 0.9373  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 00002: val_loss improved from 131932979.66667 to 45892.50301, saving model to my_model_best.hdf5\n",
      "12/12 [==============================] - 143s 12s/step - loss: 0.2984 - accuracy: 0.9104 - dice_coef: 0.9419 - val_loss: 45892.5030 - val_accuracy: 0.9247 - val_dice_coef: 0.9602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x18f7a247978>"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练\n",
    "BATCHSIZE = 1  # batch size\n",
    "EPOCHS = 2  # epochs\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "data_gen_args = dict(rotation_range=90,width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2)\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)  # 产生数据\n",
    "\n",
    "model.fit(image_datagen.flow(x_train_img,y_train_mask,batch_size=BATCHSIZE),\n",
    "          epochs=EPOCHS,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(x_val_img,y_val_mask))\n",
    "\n",
    "# 每训练完成一个epoch，在验证集上验证一次，评价指标使用dice系数和accuracy\n",
    "# 由于keras的训练阶段评价指标中不包含精度、召回率和 F1分数，所以在后边有专门的定义"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练完成，开始在验证集上验证"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "AHuQNQKo_XE8",
    "outputId": "95834f1f-956f-4cd3-f1e8-bdaba6f41c53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# 加载模型，modell为加载完参数的模型，准备验证\n",
    "from tensorflow.keras.models import load_model\n",
    "modelL=load_model('my_model_best.hdf5',\n",
    "                  custom_objects={'combine_loss':combine_loss,\n",
    "                                  'dice_coef':dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始推理...\n",
      "推理7707.png的分割掩膜...\n",
      "推理7785.png的分割掩膜...\n",
      "推理7786.png的分割掩膜...\n",
      "推理7850.png的分割掩膜...\n",
      "推理7928.png的分割掩膜...\n",
      "推理8130.png的分割掩膜...\n",
      "*************************************************************\n",
      "对验证集的测试结果：\n",
      "recall:1.000\tprecision:0.925\tF1-score:0.960\n",
      "*************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: results\\7707.png is a low contrast image\n",
      "E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: results\\7785.png is a low contrast image\n",
      "E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: results\\7786.png is a low contrast image\n",
      "E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: results\\7850.png is a low contrast image\n",
      "E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: results\\7928.png is a low contrast image\n",
      "E:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: results\\8130.png is a low contrast image\n"
     ]
    }
   ],
   "source": [
    "# 模型评估：percision，recal，F1-score\n",
    "SAVE_PRED = True  # 是否保存分割结果图\n",
    "SAVE_PATH = \"results\"  # 保存路径\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from skimage import io\n",
    "import os.path as osp\n",
    "\n",
    "val_dataset_size = x_val_img.shape[0]\n",
    "recall_list = np.array([0.0] * val_dataset_size)\n",
    "precision_list = np.array([0.0] * val_dataset_size)\n",
    "F1_list = np.array([0.0] * val_dataset_size)\n",
    "\n",
    "print(\"开始推理...\")\n",
    "for i in range(val_dataset_size):\n",
    "    print(\"推理{}的分割掩膜...\".format(val_name_list[i]))\n",
    "    val_img = x_val_img[i]\n",
    "    val_mask = y_val_mask[i]\n",
    "    y_true = np.squeeze(val_mask)\n",
    "    final_val_img = np.expand_dims(val_img,axis=0)\n",
    "    pred = modelL.predict(final_val_img)\n",
    "    y_pred=np.squeeze(pred)\n",
    "    y_pred[y_pred>0.5]=1.0\n",
    "    y_pred[y_pred<=0.5]=0.0   # 阈值为 0.5，大于 0.5 的为类别 1，否则为类别 0\n",
    "    if SAVE_PRED:\n",
    "        save_pred = y_pred * 255.0\n",
    "        save_pred = save_pred.astype(np.uint8)\n",
    "        io.imsave(osp.join(SAVE_PATH, val_name_list[i]), save_pred)\n",
    "    y_true = np.reshape(y_true, newshape=(-1))\n",
    "    y_pred = np.reshape(y_pred, newshape=(-1))\n",
    "    recall_list[i] = recall_score(y_true, y_pred)\n",
    "    precision_list[i] = precision_score(y_true, y_pred)\n",
    "    F1_list[i] = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"*************************************************************\")\n",
    "print('对验证集的测试结果：\\nrecall:%.3f\\tprecision:%.3f\\tF1-score:%.3f'%\n",
    "    (np.mean(recall_list), np.mean(precision_list), np.mean(F1_list)))\n",
    "print(\"*************************************************************\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Semantic_Segmentation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}